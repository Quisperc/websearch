# crawler.py
from random import random, gauss
from turtle import delay

from cnn_spider import CNNSpider
from kuaishu_spider import kuaishuSpider

from biqu_Spider import biquSpider
from utils.TqdmLogHandler import logger
from yinyuxiaoshuo_spider import yinyuSpider


def main():
    # åˆå§‹åŒ–ç›®å½•ç»“æ„
    # Path("origin/Chin").mkdir(parents=True, exist_ok=True)
    # Path("origin/Engl").mkdir(parents=True, exist_ok=True)
    # Path("parsed/cnn").mkdir(parents=True, exist_ok=True)
    # Path("parsed/novel").mkdir(parents=True, exist_ok=True)

    # é…ç½®çˆ¬è™«å‚æ•°
    common_config = {
        "retries": 3,
        "timeout": 15,
        "delay_range": (1, 3),
        "threads": 5
    }

    # å¯åŠ¨å°è¯´çˆ¬è™«
    # novel_spider = NovelSpider({
    #     **common_config,
    #     "delay_range": (2, 5)  # å°è¯´ç«™éœ€è¦æ›´ä¿å®ˆçš„çˆ¬å–é—´éš”
    # })
    # novel_spider.crawl(start_page=27710, end_page=27749)
    #
    # delay_time = max(3, gauss(4.0, 0.6))  # å‡å€¼1ç§’ï¼Œæ ‡å‡†å·®0.3ç§’ï¼Œæœ€ä½3ç§’
    # delay(delay_time)
    # novel_spider.crawl(start_page=27750, end_page=27802)
    #
    # delay_time = max(3, gauss(4.0, 0.6))  # å‡å€¼1ç§’ï¼Œæ ‡å‡†å·®0.3ç§’ï¼Œæœ€ä½3ç§’
    # delay(delay_time)
    # novel_spider.crawl(start_page=28166, end_page=28220)
    #
    # delay_time = max(3, gauss(4.0, 0.6))  # å‡å€¼1ç§’ï¼Œæ ‡å‡†å·®0.3ç§’ï¼Œæœ€ä½3ç§’
    # delay(delay_time)
    # novel_spider.crawl(start_page=27960, end_page=28103)
    #
    # delay_time = max(3, gauss(4.0, 0.6))  # å‡å€¼1ç§’ï¼Œæ ‡å‡†å·®0.3ç§’ï¼Œæœ€ä½3ç§’
    # delay(delay_time)
    # novel_spider.crawl(start_page=27803, end_page=27834)
    #
    # delay_time = max(3, gauss(4.0, 0.6))  # å‡å€¼1ç§’ï¼Œæ ‡å‡†å·®0.3ç§’ï¼Œæœ€ä½3ç§’
    # delay(delay_time)
    # novel_spider.crawl(start_page=27934, end_page=27989)
    #
    # delay_time = max(3, gauss(4.0, 0.6))  # å‡å€¼1ç§’ï¼Œæ ‡å‡†å·®0.3ç§’ï¼Œæœ€ä½3ç§’
    # delay(delay_time)
    # novel_spider.crawl(start_page=27835, end_page=27933)
    #
    # delay_time = max(3, gauss(4.0, 0.6))  # å‡å€¼1ç§’ï¼Œæ ‡å‡†å·®0.3ç§’ï¼Œæœ€ä½3ç§’
    # delay(delay_time)
    # novel_spider.crawl(start_page=28098, end_page=28174)


    # # å¯åŠ¨CNNçˆ¬è™«
    # cnn_spider = CNNSpider(common_config)
    # cnn_spider.crawl(max_articles=600)

    # novel_spider = biquSpider({
    #     **common_config,
    #     "delay_range": (2, 5)  # å°è¯´ç«™éœ€è¦æ›´ä¿å®ˆçš„çˆ¬å–é—´éš”
    # })
    # novel_spider.crawl(503)

    novel_spider = yinyuSpider({
        **common_config,
        "delay_range": (2, 5)  # å°è¯´ç«™éœ€è¦æ›´ä¿å®ˆçš„çˆ¬å–é—´éš”
    })
    novel_spider.crawl(1)
    logger.info("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼")
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    # logger.info("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    # logger.info(f"  å°è¯´ç« èŠ‚: {novel_spider.completed} æˆåŠŸ / {novel_spider.failed} å¤±è´¥")
    # logger.info(f"  CNNæ–°é—»: {cnn_spider.completed} æˆåŠŸ / {cnn_spider.failed} å¤±è´¥")


if __name__ == "__main__":
    main()
