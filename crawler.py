# crawler.py
import os

from utils.TqdmLogHandler import logger
from yinyuxiaoshuo_spider import yinyuSpider

def main():

    # é…ç½®çˆ¬è™«å‚æ•°
    common_config = {
        "retries": 3,
        "timeout": 30,
        "delay_range": (1, 2),
        "threads": 5
    }

    # å¯åŠ¨å°è¯´çˆ¬è™«
    # kuaishunovel_spider = kuaishuSpider({
    #     **common_config,
    #     "delay_range": (2, 5)  # å°è¯´ç«™éœ€è¦æ›´ä¿å®ˆçš„çˆ¬å–é—´éš”
    # })
    # delay_time = max(3, gauss(4.0, 0.6))  # å‡å€¼1ç§’ï¼Œæ ‡å‡†å·®0.3ç§’ï¼Œæœ€ä½3ç§’
    # delay(delay_time)
    # kuaishunovel_spider.crawl(start_page=27710, end_page=27802)

    # # å¯åŠ¨CNNçˆ¬è™«
    # cnn_spider = CNNSpider(common_config)
    # cnn_spider.crawl(max_articles=600)

    # biqunovel_spider = biquSpider({
    #     **common_config,
    #     "delay_range": (1, 2)  # å°è¯´ç«™éœ€è¦æ›´ä¿å®ˆçš„çˆ¬å–é—´éš”
    # })
    # biqunovel_spider.crawl(503)

    Englishnovel_spider = yinyuSpider({
        **common_config,
        "delay_range": (1, 2)  # å°è¯´ç«™éœ€è¦æ›´ä¿å®ˆçš„çˆ¬å–é—´éš”
    })
    Englishnovel_spider.crawl(10)
    logger.info("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼")
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    # logger.info("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    # logger.info(f"  å°è¯´ç« èŠ‚: {novel_spider.completed} æˆåŠŸ / {novel_spider.failed} å¤±è´¥")
    # logger.info(f"  CNNæ–°é—»: {cnn_spider.completed} æˆåŠŸ / {cnn_spider.failed} å¤±è´¥")


if __name__ == "__main__":
    main()
