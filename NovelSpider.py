from utils import Fetcher, Saver


class NovelSpider:
    def __init__(self):
        self.base_url = "https://www.kuaishu5.com/b121721/{}.html"
        self.fetcher = Fetcher()
        self.delay_range = (1, 3)  # éšæœºå»¶è¿ŸèŒƒå›´

    def crawl(self, pages=27870):
        """æ‰§è¡Œçˆ¬å–ä»»åŠ¡"""
        all_results = []

        for page in range(27710, pages + 1):
            url = self.base_url.format(page)
            print(f"ğŸ•¸ï¸ æ­£åœ¨çˆ¬å–ç¬¬ {page} é¡µ: {url}")

            # è·å–å¹¶ä¿å­˜åŸå§‹ç½‘é¡µ
            content = self.fetcher.fetch_and_save(url)

            # if content:
            #     # è§£æå†…å®¹
            #     page_data = Parser.parse_qidian(content)
            #     all_results.extend(page_data)
            #     print(f"âœ… ç¬¬ {page} é¡µè§£æå®Œæˆï¼Œå…± {len(page_data)} æ¡æ•°æ®")

        # ä¿å­˜ç»“æ„åŒ–æ•°æ®
        if all_results:
            Saver.save_data(all_results)
            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³ parsed/ ç›®å½•")
        else:
            print("âš ï¸ æœªè·å–åˆ°æœ‰æ•ˆæ•°æ®")